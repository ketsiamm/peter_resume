[
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5"
  },
  {
    "objectID": "projects.html#repo-for-all-my-projects",
    "href": "projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5"
  },
  {
    "objectID": "Projects/project4.html",
    "href": "Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "uncomment\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/project2.html",
    "href": "Projects/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "overall the flight data gives insights about flights in seven different airport it has important feature to visualize and analyse about flight delay .\n\n\nRead and format project data\n# Include and execute your code here\ndf_original = pd.read_json('https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json')"
  },
  {
    "objectID": "Projects/project2.html#elevator-pitch",
    "href": "Projects/project2.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "overall the flight data gives insights about flights in seven different airport it has important feature to visualize and analyse about flight delay .\n\n\nRead and format project data\n# Include and execute your code here\ndf_original = pd.read_json('https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json')"
  },
  {
    "objectID": "Projects/project2.html#questiontask-1",
    "href": "Projects/project2.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.\n\n\nRead and format data\n# Include and execute your code here\n\ndf = df_original\n\n#summing all the missing values by columns\n\nmissing_values = df.isna().sum()\n#filling the missing years values\ndf['year'] = df['year'].fillna(method ='ffill')\ndf.head()\n\n\n#filling the missing minutes_delayed_carrier values with the mean\n\nmean_d_carrier = df['minutes_delayed_carrier'].mean()\ndf['minutes_delayed_carrier'] = df['minutes_delayed_carrier'].fillna(mean_d_carrier)\n\n# replacing the -999 of num_of_delays_late_aircraft values with NaN\n\ndf['num_of_delays_late_aircraft'] = df['num_of_delays_late_aircraft'].replace(-999,np.nan)\n#dropping the NaN values\ndf.dropna(inplace=True)\n#dropping the empty string\ndf = df[df['airport_name'] != '']\ndf = df[df['month'] != '']\n\n\n\n\n# Assuming df is your DataFrame\n\n\n\n\n# Convert the first record to JSON format\nraw_json = df.head(1).to_json(orient='records')\n\n\n\n\nplot example\n# Include and execute your code here\n\nraw_json\n\n\n'[{\"airport_code\":\"DEN\",\"airport_name\":\"Denver, CO: Denver International\",\"month\":\"January\",\"year\":2005.0,\"num_of_flights_total\":12687,\"num_of_delays_carrier\":\"1041\",\"num_of_delays_late_aircraft\":928.0,\"num_of_delays_nas\":935,\"num_of_delays_security\":11,\"num_of_delays_weather\":233,\"num_of_delays_total\":3153,\"minutes_delayed_carrier\":53537.0,\"minutes_delayed_late_aircraft\":70301,\"minutes_delayed_nas\":36817.0,\"minutes_delayed_security\":363,\"minutes_delayed_weather\":21779,\"minutes_delayed_total\":182797}]'"
  },
  {
    "objectID": "Projects/project2.html#questiontask-2",
    "href": "Projects/project2.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nWhich airport has the worst delays? Discuss the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\ni am using the total number of delay and the total number of minute delay to evaluate the airport that has the worst delay and after analysis it is the Chicago O’Hare International airport that has the worst one. i choose those metrics because it sum all the differents delays that we have on the tables\n\n\nRead and format data\n# Include and execute your code here\n\n# import pandas as pd\n\ndf['minute_delayed_hours'] = df['minutes_delayed_total'] / 60\n\ndf['proportion_of_delayed_flight'] = df['num_of_delays_total']/ df['num_of_flights_total']\n\nworst_airport = df.groupby('airport_name').agg(\n    total_flights=pd.NamedAgg(column='num_of_flights_total', aggfunc='sum'),\n    total_number_of_delayed=pd.NamedAgg(column='num_of_delays_total', aggfunc='sum'),\n    average_delay=pd.NamedAgg(column='minute_delayed_hours', aggfunc='mean'),\n    proportion_delay = pd.NamedAgg(column='proportion_of_delayed_flight', aggfunc='sum')\n).round(2)\nworst_airport = worst_airport.reset_index()\n\n\nithis table shows the different number of total delay,average delay and portion delay by airport. It can help us understand which airport has the worst delay by flight \n\n\ntable example\n# Include and execute your code here\nworst_airport\n\n\n\n\n\n\ntable of the total_flights,total_number_of_delayed, average_delay and proportion_delay by airport \n\n\n\nairport_name\ntotal_flights\ntotal_number_of_delayed\naverage_delay\nproportion_delay\n\n\n\n\n0\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\n2920368\n530940\n5958.22\n15.88\n\n\n1\nChicago, IL: Chicago O'Hare International\n3149810\n695137\n6683.35\n25.40\n\n\n2\nDenver, CO: Denver International\n2243898\n424413\n3223.95\n22.24\n\n\n3\nSalt Lake City, UT: Salt Lake City International\n1271492\n187508\n1292.40\n17.46\n\n\n4\nSan Diego, CA: San Diego International\n844505\n162010\n1050.03\n23.07\n\n\n5\nSan Francisco, CA: San Francisco International\n1496085\n393741\n3395.90\n31.79\n\n\n6\nWashington, DC: Washington Dulles International\n743192\n146579\n1280.74\n22.72"
  },
  {
    "objectID": "Projects/project2.html#questiontask-3",
    "href": "Projects/project2.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nWhat is the best month to fly if you want to avoid delays of any length? Discuss the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\n_ if you want to avoid delay of any sort you should fly in november because it got the lowest delay of average of delay. i choose the hours delay because i think that no matter the amount of delay you can have what matter most is the amount of time because people can bear some minute delay even if it happen frequently_\n\n\nRead and format data\n# Include and execute your code here\ndf['month'].replace('n/a',np.nan,inplace =True)\ndf.dropna(inplace=True)\n\ndf['minute_delayed_hours'] =( df['minutes_delayed_total'] / 60 ).round(2)\nbest_months = df.groupby('month').agg(\n     average_delay=pd.NamedAgg(column='minute_delayed_hours', aggfunc='mean')\n\n).round(2)\nbest_months = best_months.reset_index()\n\n\n\n\nplot example\n# Include and execute your code here\n\n\n# Assuming 'best_months' DataFrame contains the data with the 'month' column as an ordered categorical variable\n\n# Define the order of the months\nmonth_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\n# Convert 'month' column to ordered categorical with specified order\nbest_months['month'] = pd.Categorical(best_months['month'], categories=month_order, ordered=True)\n\n# Sort 'best_months' DataFrame by the 'month' column\nbest_months_sorted = best_months.sort_values(by='month', ignore_index=True)\n\n# Plot bar chart using Plotly Express\nchart = px.bar(best_months_sorted,\n               x='month',\n               y='average_delay',\n               title='Average Delay by Month',\n               labels={'month': 'Month', 'average_delay': 'Average Delay'})\n\n# Show the chart\nchart.show()\n\n\n\n                                                \naverage delay by month"
  },
  {
    "objectID": "Projects/project2.html#questiontask-4",
    "href": "Projects/project2.html#questiontask-4",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations\nthis weather table show the number of delay flight by weather(both severe and mild), the proportion of weather delay and the proportion of weather total .\n\n\ntable example\n# Include and execute your code here\nflights = df\nweather = (flights.assign(\n    severe = flights.num_of_delays_weather, # no missing\n    nodla_nona = lambda x: (x.num_of_delays_late_aircraft\n        .replace(-999, np.nan)), #missing is -999\n    mild_late = lambda x: x.nodla_nona.fillna(x.nodla_nona.mean())*0.3,\n    mild = np.where(\n        flights.month.isin(['April', 'May', 'June', 'July', 'August']), \n            flights.num_of_delays_nas*0.4,\n            flights.num_of_delays_nas*0.65),\n    weather = lambda x: x.severe + x.mild_late + x.mild,\n    proportion_weather_delay = lambda x: x.weather / x.num_of_delays_total,\n    proportion_weather_total = lambda x:  x.weather / x.num_of_flights_total)\n    .filter(['airport_code','month','year', 'severe','mild', 'mild_late',\n    'weather', 'proportion_weather_total', \n    'proportion_weather_delay', 'num_of_flights_total', 'num_of_delays_total']))\nweather.head()\n\n\n\n\n\n\nweather table \n\n\n\nairport_code\nmonth\nyear\nsevere\nmild\nmild_late\nweather\nproportion_weather_total\nproportion_weather_delay\nnum_of_flights_total\nnum_of_delays_total\n\n\n\n\n1\nDEN\nJanuary\n2005.0\n233\n607.75\n278.4\n1119.15\n0.088212\n0.354948\n12687\n3153\n\n\n3\nORD\nJanuary\n2005.0\n306\n3519.75\n676.5\n4502.25\n0.159688\n0.490548\n28194\n9178\n\n\n4\nSAN\nJanuary\n2005.0\n56\n414.70\n204.0\n674.70\n0.092640\n0.345645\n7283\n1952\n\n\n5\nSFO\nJanuary\n2005.0\n114\n757.90\n219.9\n1091.80\n0.106268\n0.387713\n10274\n2816\n\n\n6\nSLC\nJanuary\n2005.0\n270\n561.60\n169.2\n1000.80\n0.083400\n0.396356\n12000\n2525"
  },
  {
    "objectID": "Projects/project2.html#questiontask-5",
    "href": "Projects/project2.html#questiontask-5",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 5",
    "text": "QUESTION|TASK 5\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Discuss what you learn from this graph.\nas we can see this chart the San Franscisco airport has the highest proportion of flight delayed by weather and that the Atlanta airport has the lowest one. \n\n\nplot example\n# Include and execute your code here\n\nfig = px.bar(weather, x='airport_code', y='proportion_weather_delay',\n             labels={'airport_code': 'Airport Code', 'proportion_weather_delay': 'Proportion of Delayed Flights due to Weather'},\n             title='Proportion of Delayed Flights due to Weather by Airport')\n\n\nfig.update_layout(xaxis={'categoryorder':'total ascending'})\n\nfig.show()"
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Projects/project1.html",
    "href": "Projects/project1.html",
    "title": "Client Report - [what’s in a name ]",
    "section": "",
    "text": "_ Overall the data contains key insight about the names accros the United State from 1920 to 2015. Christian names were the most popular ones but with time other name started to become more poular than the Christian names_ _ _\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Projects/project1.html#elevator-pitch",
    "href": "Projects/project1.html#elevator-pitch",
    "title": "Client Report - [what’s in a name ]",
    "section": "",
    "text": "_ Overall the data contains key insight about the names accros the United State from 1920 to 2015. Christian names were the most popular ones but with time other name started to become more poular than the Christian names_ _ _\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Projects/project1.html#questiontask-1",
    "href": "Projects/project1.html#questiontask-1",
    "title": "Client Report - [what’s in a name ]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nHow does your name at your birth year compare to its use historically?\n_ compared to the average of my name in history which is 4955.21 my name during my birth year is with a total 3137 is below the average _\n\n\nRead and format data\n# Include and execute your code here\n\n\npeter_in_history = df.query('name == \"Peter\"')\naverage = peter_in_history['Total'].mean()\n\n\n\n\nplot example\n# Include and execute your code here\n\n\n\n# scatter\nscatter_plot = px.scatter(\n    peter_in_history,\n    x=\"year\",\n    y=\"Total\",\n    title=\"Scatter Plot with Trendline for Peter's Historical Data\",\n    trendline=\"ols\"  # Add a trendline using Ordinary Least Squares regression\n)\n# annotation\nscatter_plot.add_annotation(\n    text=\"Peter in 2000\",\n    x=2000,\n    y=3137,\n    showarrow=True,\n    arrowhead=7,\n    arrowcolor='red'\n\n)\n# Show the plot\nscatter_plot.show()\n\n\n\n                                                \n\n\n_ here is a table of my name (Peter) in my birthdate and the highest peter in history to see the difference _\n\n\ntable example\n# Include and execute your code here\n\npeter_in_2000 = df.query('name == \"Peter\" and year == 2000')\npeter_in_history = df.query('name == \"Peter\"')\nPeter_max_total = peter_in_history[peter_in_history['Total'] == peter_in_history['Total'].max()].filter(['year', 'Total'])\n\nprint(\"peter_in_2000:\")\nprint(peter_in_2000)\n\nprint(\"\\nPeter_max_total:\")\nprint(Peter_max_total)\n\n\npeter_in_2000:\n         name  year    AK    AL    AR    AZ     CA    CO    CT    DC  ...   \n303695  Peter  2000  11.0  14.0  11.0  40.0  379.0  66.0  72.0  20.0  ...  \\\n\n          TN     TX    UT    VA    VT    WA    WI   WV   WY   Total  \n303695  26.0  147.0  24.0  62.0  12.0  68.0  70.0  0.0  0.0  3137.0  \n\n[1 rows x 54 columns]\n\nPeter_max_total:\n        year    Total\n303651  1956  11321.0"
  },
  {
    "objectID": "Projects/project1.html#questiontask-2",
    "href": "Projects/project1.html#questiontask-2",
    "title": "Client Report - [what’s in a name ]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\n_ My guess is that she was probably born in 1990, and she is 34 years old because that is the year that had the highest record of people born named Brittany. I wouldn’t guess that she was born in 1971 and that she is 51 because that is the year with the lowest record of people named Brittany. _\n\n\nRead and format data\n# Include and execute your code here\nbrittany = df.query('name == \"Brittany\"')# query all the brittany\nbrittany_max = brittany[['year','Total']]# query the brittany their birth year and the total name for that year\n\n\n\n\nplot example\n# Include and execute your code here\n\n# Filter data for the name 'Brittany'\nbrittany = df.query('name == \"Brittany\"')\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# brittany\nbrittany = df.query('name == \"Brittany\"')\n\n# Create a line chart\nchart = px.line(\n    brittany,\n    x=\"year\",\n    y=\"Total\",\n    title=\"Line Chart with Trendline and Annotation\"\n)\n\n# Add a trace for the trendline\ntrendline_trace = go.Scatter(\n    x=[1990],\n    y=[32562.5],\n    mode='markers',\n    marker=dict(color='green'),\n    name='Highest Brittany in 1990'\n)\n\nchart.add_trace(trendline_trace)\n\n# Update traces to add a trendline\nchart.update_traces(\n    mode='lines',\n    line=dict(color='blue'),\n    selector=dict(type='scatter')\n)\n\n# Add a text annotation\nchart.add_annotation(\n    text=\"Highest Brittany in 1990\",\n    x=1990,\n    y=32562.5,\n    showarrow=True,\n    arrowhead=2,\n    arrowcolor='green'\n)\n\n# Show the plot\nchart.show()\n\n\n\n                                                \n\n\n_ here is a table of the name Brittany, the total and the year where it reach it peak\n\n\ntable example\n# Include and execute your code here\n\nbrittany_max_total = brittany_max[brittany_max['Total'] == brittany_max['Total'].max()].filter(['year', 'Total'])\n\nbrittany_max_total# return the year with the most Brittany\n\n\n\n\n\n\ntable of the year with the most Brittany \n\n\n\nyear\nTotal\n\n\n\n\n53227\n1990\n32562.5"
  },
  {
    "objectID": "Projects/project1.html#questiontask-3",
    "href": "Projects/project1.html#questiontask-3",
    "title": "Client Report - [what’s in a name ]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\n_ They all mostly followed the same pattern Mary: a slightly increase in 1921 a decrease in 1936 a peak in 1950 and it continues to decreased to the end Paul: an increase that reach its peak in 1953 and a decrease in the end Martha: a slightly increase that reach its peak in 1947 and a decrease in the end Peter: an increase that reach its peak in 1956 and a constant decrease\n\n\nRead and format data\n# Include and execute your code here\n# list = ['Mary'.'Martha','Peter','Paul']\nfiltered = df.query(\"name==['Mary','Martha','Peter','Paul']&year&gt;= 1920 & year&lt;=2000\")\nfiltered_1 = filtered.filter(['name','year','Total'])\n# average = filtered_1['Total'].mean()\n\n\n\n\nCode\n# filtered_1.head()\n# average\n\n\n\n\nplot example\n# Include and execute your code here\n\nchart = px.line(filtered_1, \n    x=\"year\", \n    y=\"Total\", \n    color='name', \n    line_group='name',  \n    title='Line Chart of Mary, Martha, Peter, and Paul')\n\n\nchart.show()"
  },
  {
    "objectID": "Projects/project1.html#questiontask-4",
    "href": "Projects/project1.html#questiontask-4",
    "title": "Client Report - [what’s in a name ]",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage? i choose the name Bella from the Twillight moovie. I noticed that overall from the year 2000 to 2010 there was an increase from 245 to 5109 an in crease of 1985.71%. From the movie realease in 2008 to the next year we witneesed an increseased of 53.78% compared to the increased from 2000 to the release year where it was 36.32%\n\n\nplot example\n# Include and execute your code here\n\nbella = df.query('name == \"Bella\"')\nyear_bella = bella.query('year == 2008')\nyear_bella\n\nchart = px.line(bella, \n    x=\"year\", \n    y=\"Total\",  \n    title='Line Chart of Total over Years for Selected Names',\n    \n    )\n\nchart.add_annotation(\n    text=\"Release date\",\n    x=2008,\n    y=2778,\n    showarrow=True,\n    arrowhead=2,\n    arrowcolor='red'\n)\n\n\nchart.show()\n\n\n\n                                                \n\n\n\n\ntable example\n# Include and execute your code here\nJohn = df.query('name == \"John \" & name == \"Peter\"')\narrange = df.filter(['name','year'])\narrange\ndrop = arrange.drop(columns= ['name'])\ndrop\n\n\n\n\n\n\nNot much of a table \n\n\n\nyear\n\n\n\n\n0\n2005\n\n\n1\n2007\n\n\n2\n2008\n\n\n3\n2009\n\n\n4\n2010\n\n\n...\n...\n\n\n393379\n2011\n\n\n393380\n2012\n\n\n393381\n2013\n\n\n393382\n2014\n\n\n393383\n2015\n\n\n\n\n393384 rows × 1 columns"
  },
  {
    "objectID": "Projects/project3.html",
    "href": "Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Overall the lahmansbaseball database gives us important insight about baseball team and players here we can get insight with player school, name and performance .\n\n\nRead and format project data\n# Include and execute your code here\n\n\n\nsqlite_file = \"C:\\\\Users\\\\ketsi\\\\OneDrive\\\\Desktop\\\\lahmansbaseballdb.sqlite\"\ncon = sqlite3.connect(sqlite_file)\n\nq = 'SELECT * FROM allstarfull'\nresults = pd.read_sql_query(q, con)\n\nprint(results)\n\n\n        ID   playerID  yearID  gameNum        gameID teamID  team_ID lgID  GP   \n0        1  gomezle01    1933        0  ALS193307060    NYA      921   AL   1  \\\n1        2  ferreri01    1933        0  ALS193307060    BOS      912   AL   1   \n2        3  gehrilo01    1933        0  ALS193307060    NYA      921   AL   1   \n3        4  gehrich01    1933        0  ALS193307060    DET      919   AL   1   \n4        5  dykesji01    1933        0  ALS193307060    CHA      915   AL   1   \n...    ...        ...     ...      ...           ...    ...      ...  ...  ..   \n5337  5369  smithwi04    2019        0  ALS201907090    SFN     2920   NL   1   \n5338  5370  sorokmi01    2019        0  ALS201907090    ATL     2897   NL   1   \n5339  5371  storytr01    2019        0  ALS201907090    COL     2904   NL   1   \n5340  5372  woodrbr01    2019        0  ALS201907090    MIL     2911   NL   1   \n5341  5373  yateski01    2019        0  ALS201907090    SDN     2918   NL   0   \n\n      startingPos  \n0             1.0  \n1             2.0  \n2             3.0  \n3             4.0  \n4             5.0  \n...           ...  \n5337          NaN  \n5338          NaN  \n5339          NaN  \n5340          NaN  \n5341          NaN  \n\n[5342 rows x 10 columns]"
  },
  {
    "objectID": "Projects/project3.html#elevator-pitch",
    "href": "Projects/project3.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Overall the lahmansbaseball database gives us important insight about baseball team and players here we can get insight with player school, name and performance .\n\n\nRead and format project data\n# Include and execute your code here\n\n\n\nsqlite_file = \"C:\\\\Users\\\\ketsi\\\\OneDrive\\\\Desktop\\\\lahmansbaseballdb.sqlite\"\ncon = sqlite3.connect(sqlite_file)\n\nq = 'SELECT * FROM allstarfull'\nresults = pd.read_sql_query(q, con)\n\nprint(results)\n\n\n        ID   playerID  yearID  gameNum        gameID teamID  team_ID lgID  GP   \n0        1  gomezle01    1933        0  ALS193307060    NYA      921   AL   1  \\\n1        2  ferreri01    1933        0  ALS193307060    BOS      912   AL   1   \n2        3  gehrilo01    1933        0  ALS193307060    NYA      921   AL   1   \n3        4  gehrich01    1933        0  ALS193307060    DET      919   AL   1   \n4        5  dykesji01    1933        0  ALS193307060    CHA      915   AL   1   \n...    ...        ...     ...      ...           ...    ...      ...  ...  ..   \n5337  5369  smithwi04    2019        0  ALS201907090    SFN     2920   NL   1   \n5338  5370  sorokmi01    2019        0  ALS201907090    ATL     2897   NL   1   \n5339  5371  storytr01    2019        0  ALS201907090    COL     2904   NL   1   \n5340  5372  woodrbr01    2019        0  ALS201907090    MIL     2911   NL   1   \n5341  5373  yateski01    2019        0  ALS201907090    SDN     2918   NL   0   \n\n      startingPos  \n0             1.0  \n1             2.0  \n2             3.0  \n3             4.0  \n4             5.0  \n...           ...  \n5337          NaN  \n5338          NaN  \n5339          NaN  \n5340          NaN  \n5341          NaN  \n\n[5342 rows x 10 columns]"
  },
  {
    "objectID": "Projects/project3.html#questiontask-1",
    "href": "Projects/project3.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report\nAfter analysing of the table there is no BYU-Idaho player that play Baseball at that level\n\n\nRead and format data\n# Include and execute your code here\n\np = '''\n\nSELECT allstarfull.playerID, schools.schoolID, schools.name_full, Salaries.salary, allstarfull.yearID, allstarfull.teamID\nFROM allstarfull\nJOIN CollegePlaying ON CollegePlaying.playerID = allstarfull.playerID\nJOIN schools ON CollegePlaying.schoolID = schools.schoolID\nJOIN Salaries ON allstarfull.playerID = Salaries.playerID\nWHERE schools.name_full = \"Brigham Young University-Idaho\"\nORDER BY Salaries.salary DESC\nLIMIT 5;\n\n\n'''\ncon = sqlite3.connect(sqlite_file)\nresults = pd.read_sql_query(p,con)\nresults.tail()\n\n\n\n\n\n\n\n\n\nplayerID\nschoolID\nname_full\nsalary\nyearID\nteamID"
  },
  {
    "objectID": "Projects/project3.html#questiontask-2",
    "href": "Projects/project3.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats) Write an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report. Use the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results. Now calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results\nthe analysis shows the first five batting average with at least 1 at bat, the first five batting average with at least 10 at bat and the Table per player with at least 100 at bat. Overall this three table gives us insight about batting averages \n\n\nRead and format data\n# Include and execute your code here\n\nq = '''\nSELECT playerID , yearID, ROUND(H*1.0/AB,3) AS Batting_average \nFROM Batting\nWHERE AB&gt;1\nORDER BY Batting_average DESC, playerID \nLIMIT 5\n'''\ncon = sqlite3.connect(sqlite_file)\nresults = pd.read_sql_query(q,con)\nresults.head()\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nBatting_average\n\n\n\n\n0\naybarma01\n2001\n1.0\n\n\n1\nbirasst01\n1944\n1.0\n\n\n2\nbrideji01\n1953\n1.0\n\n\n3\nbrownha01\n1951\n1.0\n\n\n4\nbrownpe01\n1894\n1.0\n\n\n\n\n\nTable of the first five batting average with at least 1 at bat\n\n\n\n\nplot example\n# Include and execute your code here\n\nq2 = '''\nSELECT playerID , yearID, ROUND(H*1.0/AB,3) AS Batting_average \nFROM Batting\nWHERE AB&gt;=10\nORDER BY Batting_average DESC, playerID \nLIMIT 5\n'''\ncon = sqlite3.connect(sqlite_file)\nresults = pd.read_sql_query(q2,con)\nresults.head()\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nBatting_average\n\n\n\n\n0\nnymanny01\n1974\n0.643\n\n\n1\ncarsoma01\n2013\n0.636\n\n\n2\naltizda01\n1910\n0.600\n\n\n3\njohnsde01\n1975\n0.600\n\n\n4\nsilvech01\n1948\n0.571\n\n\n\n\n\nTable of the first five batting average with at least 10 at bat\n\n\n\n\ntable example\n# Include and execute your code here\n\nq3 ='''\nSELECT playerID, ROUND(SUM(H)*1.0/SUM(AB), 3) AS Batting_average \nFROM Batting\nWHERE AB &gt;= 100\nGROUP BY playerID\nORDER BY Batting_average DESC, playerID \nLIMIT 5;\n\n'''\ncon = sqlite3.connect(sqlite_file)\nresults = pd.read_sql_query(q3,con)\nresults.head()\n\n\n\n\n\n\nTable per player with at least 100 at bat \n\n\n\nplayerID\nBatting_average\n\n\n\n\n0\nhazlebo01\n0.403\n\n\n1\ndaviscu01\n0.381\n\n\n2\nfishesh01\n0.374\n\n\n3\nwoltery01\n0.370\n\n\n4\ncobbty01\n0.366"
  },
  {
    "objectID": "Projects/project3.html#questiontask-3",
    "href": "Projects/project3.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Plotly Express to visualize the comparison. What do you learn?\n_ From the Chart showing comparing the Yankee and the Dodgers winning ratio we notice that overall the yankees performed better than the dodgers having the highest winning ratio thee years (1927 :0.71 victory per game, 1939:0.7 victory per game and 1998:0.7 victory per game)_\n\n\nRead and format data\n# Include and execute your code here\n\nq4 = '''\nSELECT teamID , name,ROUND(W*1.0/G,2) AS Wining_ratio,Round(L*1.0/G) AS Losing_ratio, yearID\nFROM Teams\nWHERE name = 'New York Yankees'OR name='Los Angeles Dodgers'\n\n\n'''\ncon = sqlite3.connect(sqlite_file)\nresults = pd.read_sql_query(q4,con)\nresults\n\n\n\n\n\n\nNew York Yankees and Los Angeles Dodgers winning and lossing ratio \n\n\n\nteamID\nname\nWining_ratio\nLosing_ratio\nyearID\n\n\n\n\n0\nNYA\nNew York Yankees\n0.37\n1.0\n1913\n\n\n1\nNYA\nNew York Yankees\n0.45\n1.0\n1914\n\n\n2\nNYA\nNew York Yankees\n0.45\n1.0\n1915\n\n\n3\nNYA\nNew York Yankees\n0.51\n0.0\n1916\n\n\n4\nNYA\nNew York Yankees\n0.46\n1.0\n1917\n\n\n...\n...\n...\n...\n...\n...\n\n\n164\nNYA\nNew York Yankees\n0.56\n0.0\n2017\n\n\n165\nLAN\nLos Angeles Dodgers\n0.56\n0.0\n2018\n\n\n166\nNYA\nNew York Yankees\n0.62\n0.0\n2018\n\n\n167\nLAN\nLos Angeles Dodgers\n0.65\n0.0\n2019\n\n\n168\nNYA\nNew York Yankees\n0.64\n0.0\n2019\n\n\n\n\n169 rows × 5 columns\n\n\n\n\n\nplot example\n# Include and execute your code here\nchart = px.line(results,\n    x= \"yearID\" ,\n    y=\"Wining_ratio\",\n    color= \"name\",\n    title= \"Yankees and Dodger winning ratio over the years\"\n)\nchart.show()"
  },
  {
    "objectID": "Projects/project5.html",
    "href": "Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "uncomment\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Ketsiammen Peter’s CV",
    "section": "",
    "text": "aspiring Data Scientist\nMy linkedin page"
  },
  {
    "objectID": "resume.html#profile-summary",
    "href": "resume.html#profile-summary",
    "title": "Ketsiammen Peter’s CV",
    "section": "Profile summary",
    "text": "Profile summary\nPassionate data science and tech enthusiast eager to apply my academic knowledge and hands-on skills in a dynamic setting. Detail-oriented and dedicated individual with a strong foundation in Microsoft Office Suite, specializing in Word, PowerPoint, and Excel for document creation, presentations, and data entry. Proficient in leveraging Python for efficient problem-solving and scripting, with a focus on clean code practices. Experienced in MySQL for database management, showcasing abilities in data retrieval, manipulation, and basic optimization. Excited about expanding expertise in advanced database design and query optimization. Recognized for adaptability, quick learning, and a commitment to using technology for effective problem resolution. Seeking opportunities to contribute and grow in a challenging environment."
  },
  {
    "objectID": "resume.html#language",
    "href": "resume.html#language",
    "title": "Ketsiammen Peter’s CV",
    "section": "Language",
    "text": "Language\nfrench(native), english(advanced)"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Ketsiammen Peter’s CV",
    "section": "Education",
    "text": "Education\n2022-now Brigham Young University, Idaho.\nstudying Data Science"
  },
  {
    "objectID": "resume.html#experience",
    "href": "resume.html#experience",
    "title": "Ketsiammen Peter’s CV",
    "section": "Experience",
    "text": "Experience\nMarch 2023 Allen Design Company\nCollaborated with Allen Designs, a small business in Las Vegas, Nevada, specializing in crafting functional and aesthetically pleasing interior spaces to address the needs in managing finances and executing effective digital marketing strategies.\nimproved company website by proposing various website template, Logos ,slogans and names.\nAdvised various marketing plans to help company reach more customers."
  },
  {
    "objectID": "resume.html#skils",
    "href": "resume.html#skils",
    "title": "Ketsiammen Peter’s CV",
    "section": "skils",
    "text": "skils\n\ncomputer skills\nMicrosoft Office Suite: Competent in utilizing essential functions of Word for document creation, PowerPoint for basic presentations, and Excel for fundamental data entry and spreadsheet tasks.\nProgramming Languages and Database Management: Python: Proficient in writing and debugging Python code, with a focus on problem-solving and scripting tasks. MySQL: Competent in database management using MySQL, including data retrieval, manipulation, and basic optimization. Eager to expand skills in database design and advanced query optimization."
  },
  {
    "objectID": "Projects/project4.html#elevator-pitch",
    "href": "Projects/project4.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "Elevator pitch",
    "text": "Elevator pitch\n_ Overall the dwelling ml data gives us great insight about different houses from 1873 to 2013. Classifying houses as built before or after 1980 is crucial for real estate decisions. Our project simplifies this task, benefiting everyone from homebuyers to investors. _\n\n\nRead and format project data\n# Include and execute your code here\n\nurl = \"https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv\"\ndata = pd.read_csv(url)\ndata.describe()\n\n\n\n\n\n\n\n\n\nabstrprd\nlivearea\nfinbsmnt\nbasement\nyrbuilt\ntotunits\nstories\nnocars\nnumbdrm\nnumbaths\n...\narcstyle_THREE-STORY\narcstyle_TRI-LEVEL\narcstyle_TRI-LEVEL WITH BASEMENT\narcstyle_TWO AND HALF-STORY\narcstyle_TWO-STORY\nqualified_Q\nqualified_U\nstatus_I\nstatus_V\nbefore1980\n\n\n\n\ncount\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n...\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n22913.000000\n\n\nmean\n1118.980099\n1510.783485\n330.511936\n524.501942\n1963.685506\n1.018461\n1.419849\n1.362589\n2.522062\n2.351416\n...\n0.001615\n0.011827\n0.014010\n0.007201\n0.208921\n0.673853\n0.326147\n0.945926\n0.054074\n0.624929\n\n\nstd\n152.603144\n787.018142\n469.912502\n567.653028\n36.928700\n0.256309\n0.568886\n1.097619\n0.884602\n1.117339\n...\n0.040153\n0.108111\n0.117532\n0.084555\n0.406546\n0.468812\n0.468812\n0.226169\n0.226169\n0.484152\n\n\nmin\n100.000000\n293.000000\n0.000000\n0.000000\n1873.000000\n0.000000\n1.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n1112.000000\n975.000000\n0.000000\n0.000000\n1940.000000\n1.000000\n1.000000\n0.000000\n2.000000\n2.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n\n\n50%\n1112.000000\n1302.000000\n0.000000\n401.000000\n1963.000000\n1.000000\n1.000000\n2.000000\n2.000000\n2.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n0.000000\n1.000000\n0.000000\n1.000000\n\n\n75%\n1114.000000\n1823.000000\n716.000000\n959.000000\n2002.000000\n1.000000\n2.000000\n2.000000\n3.000000\n3.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n0.000000\n1.000000\n\n\nmax\n9279.000000\n21503.000000\n4320.000000\n9025.000000\n2013.000000\n10.000000\n4.000000\n17.000000\n9.000000\n11.000000\n...\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 50 columns\n\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Projects/project4.html#questiontask-1",
    "href": "Projects/project4.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCreate 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.\n_ from the different charts made we can conclude that we can some variable changes acoording to the times and that can help a machine learnimg algorithm in fiding pattern whithin the data and classify it ._\n\n\nplot example\n# Include and execute your code here\nchart = px.scatter(data,\n    x=\"before1980\", \n    y=\"sprice\",\n    title='sales prices before and after 1980'\n)\n\nchart.show()\n\n\n\n                                                \n\n\n\n\ntable example\n# Include and execute your code here\nimport plotly.express as px\n\n# Assuming 'data' is your DataFrame containing the specified columns\nhouse_features = data[['numbdrm', 'numbaths', 'sprice', 'nocars']]\n\n# Create the scatter plot\nchart = px.scatter(data, x=\"before1980\", y='numbaths', title='Number of Bedrooms vs Year Before 1980')\n\n# Update the scatter plot\nchart.update_traces(marker=dict(size=12, opacity=0.8))  # Customize marker size and opacity\n\n# Update layout\nchart.update_layout(\n    xaxis_title=\"Year Before 1980\",\n    yaxis_title=\"Number of Bedrooms\",\n    legend_title=\"Price\",  # Update legend title\n)\n\n# Show the scatter plot\nchart.show()"
  },
  {
    "objectID": "Projects/project4.html#questiontask-2",
    "href": "Projects/project4.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nBuild a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.\n_ for my model i use a the Random Forest Classifier. In essence, a Random Forest Classifier combines the opinions of many decision-makers (trees) to make a more reliable prediction. i tried the decision tree classifier and the MLP Classifier _\n\n\nRead and format data\n# Include and execute your code here\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfeatures = data[['sprice', 'numbdrm', 'numbaths','livearea','nocars','syear','stories','abstrprd','basement']]\ntarget = data['before1980']\n\n# Split the data into training and testing sets\ntrain_data, test_data, train_targets, test_targets = train_test_split(features, target, test_size=0.3, random_state=42)\n\n# Initialize RandomForestClassifier\nmodel = RandomForestClassifier()\n\n# Train the classifier on the training data\nmodel.fit(train_data, train_targets)\n\n# Predict on the testing data\ny_pred = model.predict(test_data)\n\n# Calculate accuracy\naccuracy = accuracy_score(test_targets, y_pred)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n\nAccuracy: 0.91"
  },
  {
    "objectID": "Projects/project4.html#questiontask-3",
    "href": "Projects/project4.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nJustify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features.\n_ i decided to choose the Random Forest Classifier because it uses more trees to predict. for the features i notice that features like the sales price and the number of bedroom clearly changes over time. -for the sales price as we can see it actually see that the prices increase and decreases over time meaning that the prices are not constant which indicates that it is a good feature to use for our model because it allows the model to capture trends and differences in property values. -for the number of bedroom we can clearly see that most of the houses whith highest room are build before 1950 _\n\n\nRead and format data\n# Include and execute your code here\n\nimport plotly.express as px\n\n# Assuming 'data' is your DataFrame containing 'yrbuilt', 'sprice', and 'annotation' columns\n\n# Create scatter plot\nimport plotly.express as px\n\n# Assuming 'data' is your DataFrame containing 'yrbuilt', 'sprice', and 'annotation' columns\n\n# Create scatter plot\nchart = px.scatter(data, x=\"yrbuilt\", y=\"sprice\", color=\"sprice\", \n                   title=\"Year Built vs. Selling Price\", \n                   labels={\"yrbuilt\": \"Year Built\", \"sprice\": \"Selling Price\"},\n                   hover_name=\"sprice\",  # Change this to the actual column name containing annotations\n                   hover_data={\"yrbuilt\": True, \"sprice\": True})  # Include additional columns as needed\n\n# Show the plot\nchart.show()\n\n\n\n                                                \n\n\ninclude figures in chunks and discuss your findings in the figure.\n\n\nplot example\n# Include and execute your code here\n\nimport plotly.express as px\n\n# Assuming 'data' is your DataFrame containing the specified columns\nhouse_features = data[['numbdrm', 'numbaths', 'sprice', 'nocars']]\n\n# Create the scatter plot\nchart = px.scatter(data, x=\"yrbuilt\", y='numbdrm', title='Number of Bedrooms over years')\n\n# Update the scatter plot\nchart.update_traces(marker=dict(size=12, opacity=0.8))  # Customize marker size and opacity\n\n# Update layout\nchart.update_layout(\n    xaxis_title=\"Years\",\n    yaxis_title=\"number of bedrooms\",\n    legend_title=\"Price\",  # Update legend title\n)\n\n# Show the scatter plot\nchart.show()"
  },
  {
    "objectID": "Projects/project4.html#questiontask-4",
    "href": "Projects/project4.html#questiontask-4",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nDescribe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.\n_ to evaluate the quality of my classification model i used the F1 score and the precision score. precision measures the accuracy of positive predictions, while the F1 score provides a balanced measure of precision and recall. Both metrics are valuable for evaluating classifier performance._\n\n\ntable example\n# Include and execute your code here\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\n\nfeatures = data[['sprice', 'numbdrm', 'numbaths', 'livearea', 'nocars', 'syear', 'stories', 'abstrprd', 'basement']]\ntarget = data['before1980']\n\n# Split the data into training and testing sets\ntrain_data, test_data, train_targets, test_targets = train_test_split(features, target, test_size=0.3, random_state=42)\n\n# Initialize RandomForestClassifier\nmodel = RandomForestClassifier()\n\n# Train the classifier on the training data\nmodel.fit(train_data, train_targets)\n\n# Predict on the testing data\ny_pred = model.predict(test_data)\n\n# Calculate the F1 score\nf1 = f1_score(test_targets, y_pred, average='weighted')\n\nprint(\"F1 Score:\", f1)\n\n\nF1 Score: 0.9100461683272536\n\n\n\n\nRead and format data\n# Include and execute your code here\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score\nfrom sklearn.model_selection import train_test_split\n\nfeatures = data[['sprice', 'numbdrm', 'numbaths', 'livearea', 'nocars', 'syear', 'stories', 'abstrprd', 'basement']]\ntarget = data['before1980']\n\n# Split the data into training and testing sets\ntrain_data, test_data, train_targets, test_targets = train_test_split(features, target, test_size=0.3, random_state=42)\n\n# Initialize RandomForestClassifier\nmodel = RandomForestClassifier()\n\n# Train the classifier on the training data\nmodel.fit(train_data, train_targets)\n\n# Predict on the testing data\ny_pred = model.predict(test_data)\n\n# Calculate the precision score\nprecision = precision_score(test_targets, y_pred, average='weighted')\n\nprint(\"Precision Score:\", precision)\n\n\nPrecision Score: 0.9088643248362581"
  }
]